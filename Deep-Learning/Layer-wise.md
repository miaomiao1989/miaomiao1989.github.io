---
layout: post 
---
#**逐层学习**

####前面的博文中我们提到过，针对深度学习中出现的问题，解决的方法主要有两类，一类是提高数据量，采用自编码+逐层学习，一类是利用CNN减少参数数量。

####这里主要讨论的是第一中方法，自编码+逐层学习。最经典的是hinton在文献[1]中提出的结构：
![](../images/Layer-1.jpg)

####坐标图表示每层由RBM组成，每层单独训练权$$W$$之后，将输出作为下层的输入，继续单独训练权值。当网络的权值都训练完成之后，将结构展开，形成上图的中间结构。由编码过程和解码过程构成具有四层结构的自编码器。再利用重构误差，反向传播，对权值进行微调。

####同理，前馈神经网络的逐层学习和精调结构为：
![](../images/Layer-4.jpg)

####<center>逐层学习</center>
![](../images/Layer-3.jpg)

####<center>展开与精调</center>

####其中$$W$$为权值，$$x$$为输入，$$z,\overline{z},\overset{=}{z}$$为编码。