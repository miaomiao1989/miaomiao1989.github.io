---
layout: default
---

#**RBM**

####**展开与精调**

####当完成了RBM的逐层学习之后，得到了每层的权值，需要对权值进行精调。将网络进行展开为：
！[]()

####未分类情况下，将所有训练好的权重和偏置拉成一个列向量，记为向量$$w\in R^{n}，n$$为网络中所有的参数个数之和。在对权调整的过程中，是将$$w$$作为优化问题的初始值，通过优化问题迭代求解$$w$$，优化目标函数为：

$$\min -\frac{1}{N}\underset{i}{\sum}\underset{j}{\sum}(X.*\log(X'))+(1-X).*(1-\log(X'))_{ij}$$

####其中$$X,X',N$$分别表示输入训练样本，输入重构样本，和样本个数。

####在hiton(2006)的文章中称上述目标函数为交叉熵误差，作为fine-tuning的误差函数，即:

$$\min -\underset{i}{\sum}X_{i}\log(X'_{i})-\underset{i}{\sum}(1-X_{i})\log(1-X'_{i})$$

####这一目标函数是利用共轭梯度法(点这里-共轭梯度法简介)求解下降方向，用线性搜索法(点这里--线性搜索法)求解每次下降的迭代解。